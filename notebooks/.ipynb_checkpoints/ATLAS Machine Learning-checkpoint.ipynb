{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. $H\\rightarrow b\\bar{b}$ via Machine Learning\n",
    "\n",
    "Machine learning algorithms are one of the ways with which we create Artificial Intelligence. The distinguishing featuere of machine learning compared to usual programming is training. Instead of programming the steps to get to the solution to a problem we program a machine learning algorithm to be trained to learn the steps towards the desired solution. \n",
    "\n",
    "On the ATLAS $H\\rightarrow b\\bar{b}$ analysis, using a BDT allows us to extract information about the correlations between the different kinematic and topolical variables to improve discrimination between signal and background. \n",
    "\n",
    "In this exercise you will use a Boosted Decision Tree algorithm to classify $H\\rightarrow b\\bar{b}$ events instead of sequential cuts. \n",
    "\n",
    "### 1.1 What is a Boosted Decision Tree?\n",
    "\n",
    "The Boosted Decision Tree algorithm has been very successful at making classifications in particle physics problems. It works by building a *forest* of _decision trees_ where each decision tree consists of a set of binary decisions that lead to classification. A weighted average of the classifications is then taken to give a final BDT output decision score. \n",
    "\n",
    "\n",
    "![BDT](images/bdt.png)\n",
    "\n",
    "\n",
    "\n",
    "### 1.2 Using BDTs\n",
    "\n",
    "The algorithm for doing the $H\\rightarrow b\\bar{b}$ can be summarised with the following 6 steps:\n",
    "\n",
    "* Import scikit-learn library and load data.\n",
    "* Training BDTs using supervised learning. \n",
    "* Score events using the BDT. \n",
    "* Calculate sensitivity. \n",
    "\n",
    "\n",
    "### Importing libraries and loading \n",
    "\n",
    "We will be using the scikit-learn python library which has an implementation of the AdaBoost classifier that is commonly used in the ATLAS analysis. \n",
    "\n",
    "\n",
    "In the code below we first import the AdaBoost Classifier and then import the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishankhurana/anaconda3/lib/python3.6/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: The mpl_toolkits.axes_grid module was deprecated in version 2.1. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist provies the same functionality instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from ucl_masterclass import *\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "df_even= pd.read_csv('../data-v1/VHbb_data_2jet_even.csv')\n",
    "df_odd = pd.read_csv('../data-v1/VHbb_data_2jet_odd.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "\n",
    "You may have wondered why the above data is loaded into two data frames labelled odd and even. We do this to avoid *overtraining*. But before we go into that, let's cover the basics of training. \n",
    "\n",
    "The BDT is given a set of training events that have a Class label of 1 for signal and 0 for background. During the training phase, the BDT's goal is to *learn* how to map input variables given to it (kinematic and topological quantities of the event) to 0 for background and 1 for signal. \n",
    "\n",
    "To ensure that the BDT is learning general features about the signal and background process and not just **artifacts** unique to the training data set, we split the data set into a training and validation set. Two BDTs are trained with one being trained on *even* events and tested on *odd* events and the other being trained on *odd* events and tested on *even* events.\n",
    "\n",
    "**In the section below we extract the input (x) and target values (y) used to train the BDT.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of variables used in training\n",
    "\n",
    "variables = ['dRBB','mBB',\n",
    "                     'pTB1', 'pTB2', 'MET',\n",
    "                     'dPhiVBB','dPhiLBmin','Mtop',\n",
    "                     'dYWH', 'mTW', 'pTV',]\n",
    "\n",
    "# Even events\n",
    "\n",
    "x_even = df_even[variables].as_matrix()\n",
    "y_even = df_even['Class'].as_matrix()\n",
    "w_even = df_even['training_weight'].as_matrix()\n",
    "\n",
    "# Odd events\n",
    "\n",
    "x_odd = df_odd[variables].as_matrix()\n",
    "y_odd = df_odd['Class'].as_matrix()\n",
    "w_odd = df_odd['training_weight'].as_matrix()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BDTs\n",
    "\n",
    "In the code cell below we will be creating two BDTs from the AdaBoost class of algorithms. Documentation for the AdaBoostClassifier can be found here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html.\n",
    "\n",
    "We will be selecting the parameters to design our BDT classifier. The parameters we will be changing are:\n",
    "\n",
    "* Number of estimators: this is the number of trees used in the BDT. Although one may think a large number of trees will lead to an excellent classifier this is not generally the case. Once a BDT converges to the solution, adding more trees does not provide much inrease in performance but does increase the computation time. \n",
    "* Tree depth: this is the number of binary decisions within the individual decision trees. Deep trees can lead to good classifiers but is likely to lead to overfitting. This means the classifier learns features that are specific to the training examples rather than general features of the solution. \n",
    "* Learning Rate: this is step size when updating the weights to minimise the gradient. \n",
    "\n",
    "If the above parameters do not make sense, please feel free to ask your mentor! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "max_depth = 4\n",
    "learning_rate = 0.15\n",
    "\n",
    "# Add parameter arguments below\n",
    "bdt_even = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=0.01),\n",
    "                                          learning_rate=learning_rate,\n",
    "                                          n_estimators=n_estimators\n",
    "                                          )\n",
    "\n",
    "bdt_odd = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=0.01),\n",
    "                                         learning_rate=learning_rate,\n",
    "                                         n_estimators=n_estimators\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting to Data\n",
    "\n",
    "Add the arguments to the fit function for both BDTs. Remember to train one BDT on the even data set and one on the odd data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bdt_even' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bcb8cbf553dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbdt_even\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_even\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_even\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_even\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbdt_odd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_odd\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_odd\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_odd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bdt_even' is not defined"
     ]
    }
   ],
   "source": [
    "bdt_even.fit(X= x_even,y = y_even ,sample_weight = w_even)\n",
    "\n",
    "bdt_odd.fit(X= x_odd ,y = y_odd ,sample_weight = w_odd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring events\n",
    "\n",
    "\n",
    "The decision_function returns a score for a given input variable (event). The code below illustrates how to use the function. In the code cell below: \n",
    "\n",
    "    bdt_even.decision_function(input_variables).tolist()\n",
    "\n",
    "Use the decision function to score events and save them to the pandas df. Make sure the BDT isn't scoring the same events it was trained on! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bdt_odd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-2cec271e9108>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Complete code below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_even\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decision_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbdt_odd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_even\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdf_odd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'decision_value'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbdt_even\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_odd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bdt_odd' is not defined"
     ]
    }
   ],
   "source": [
    "# Complete code below\n",
    "\n",
    "df_even['decision_value'] = bdt_odd.decision_function(x_even).tolist() \n",
    "df_odd['decision_value'] = bdt_even.decision_function(x_odd).tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b6fb9e9c53cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_even\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_odd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbdt_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msensitivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensitivity_bdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensitivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_even,df_odd])\n",
    "\n",
    "bdt_plot(df)\n",
    "sensitivity = sensitivity_bdt(df)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise: Adjust the BDT parameters and see how it affects the sensitivity achieved**\n",
    "\n",
    "### Exercise 2: In this task we will be studying the effect of sequentially adding variables to the BDT and seeing how it improves sensitivity.\n",
    "\n",
    "* Add variables to the variables list and train a BDT. \n",
    "* Note down the sensitivity achieved and the variables used. \n",
    "* In the next section you will plot the increase in sensitivity as variables are added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-76d4e67026a8>, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-76d4e67026a8>\"\u001b[0;36m, line \u001b[0;32m46\u001b[0m\n\u001b[0;31m    df_odd['decision_value'] =\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# List of variables used in training\n",
    "\n",
    "all_variables = ['dRBB','mBB',\n",
    "                     'pTB1', 'pTB2', 'MET',\n",
    "                     'dPhiVBB','dPhiLBmin','Mtop',\n",
    "                     'dYWH', 'mTW', 'pTV',]\n",
    "\n",
    "variables = ['mBB']\n",
    "\n",
    "# Even events\n",
    "\n",
    "x_even = df_even[variables].as_matrix()\n",
    "y_even = df_even['Class'].as_matrix()\n",
    "w_even = df_even['training_weight'].as_matrix()\n",
    "\n",
    "# Odd events\n",
    "\n",
    "x_odd = df_odd[variables].as_matrix()\n",
    "y_odd = df_odd['Class'].as_matrix()\n",
    "w_odd = df_odd['training_weight'].as_matrix()\n",
    "\n",
    "n_estimators = 200\n",
    "max_depth = 4\n",
    "learning_rate = 0.15\n",
    "\n",
    "# Add parameter arguments below\n",
    "bdt_even = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=0.01),\n",
    "                                          learning_rate=learning_rate,\n",
    "                                          n_estimators=n_estimators\n",
    "                                          )\n",
    "\n",
    "bdt_odd = AdaBoostClassifier(DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=0.01),\n",
    "                                         learning_rate=0.15,\n",
    "                                         n_estimators=n_estimators\n",
    "                                         )\n",
    "\n",
    "\n",
    "bdt_even.fit(X= x_even ,y = y_even ,sample_weight = w_odd)\n",
    "\n",
    "bdt_odd.fit(X= x_odd,y = y_odd ,sample_weight = w_odd)\n",
    "\n",
    "\n",
    "# Complete code below using the decision_function method\n",
    "\n",
    "df_even['decision_value'] =  \n",
    "df_odd['decision_value'] = \n",
    "\n",
    "df = pd.concat([df_even,df_odd])\n",
    "\n",
    "bdt_plot(df)\n",
    "sensitivity = sensitivity_bdt(df)\n",
    "print(sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Plotting sensitivity graph\n",
    "\n",
    "# Add the sensitivities you noted down to the list\n",
    "sensitivities = []\n",
    "\n",
    "# Add variable names to the list below. Make sure you keep the same order\n",
    "variable_names = []\n",
    "\n",
    "num_variables_used = len(sensitivities)\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(8.5,7)\n",
    "x = list(np.arange(0,num_variables_used,1))\n",
    "plt.plot(x,sensitivities,'o')\n",
    "plt.xlim(-1,9)\n",
    "plt.ylim(1,3)\n",
    "plt.xticks(x, variable_names);\n",
    "\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Sensitivity')\n",
    "\n",
    "\n",
    "# Once you have finalised your plots you can export a .png file by uncommenting the code below\n",
    "\n",
    "#plt.savefig('cut_based_variable_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "BDTs can learn correlations between variables and create a better understanding of the classification process hence leading to better signal sensitivity. They have been very popular on ATLAS and regularly win competitions on the Kaggle machine learning forum. If you are interested in doing more machine learning here are a list of online resources you may find useful: \n",
    "\n",
    "* This is a free 'nanodegree' on deep learning: https://www.youtube.com/watch?v=vOppzHpvTiQ&list=PL2-dafEMk2A7YdKv4XfKpfbTH5z6rEEj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
